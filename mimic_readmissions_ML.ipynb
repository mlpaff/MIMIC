{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Read-in-preprocessed-patient-data\" data-toc-modified-id=\"Read-in-preprocessed-patient-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Read in preprocessed patient data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Encode-categorical-features-and-scale-numerical-values\" data-toc-modified-id=\"Encode-categorical-features-and-scale-numerical-values-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Encode categorical features and scale numerical values</a></span></li></ul></li><li><span><a href=\"#Read-in-NOTEEVENTS-table\" data-toc-modified-id=\"Read-in-NOTEEVENTS-table-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Read in NOTEEVENTS table</a></span></li><li><span><a href=\"#Merge-notes-table-with-adm_processed-table\" data-toc-modified-id=\"Merge-notes-table-with-adm_processed-table-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Merge notes table with adm_processed table</a></span></li><li><span><a href=\"#Create-training-and-test-dataframes\" data-toc-modified-id=\"Create-training-and-test-dataframes-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create training and test dataframes</a></span></li><li><span><a href=\"#Preprocess-text-data\" data-toc-modified-id=\"Preprocess-text-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Preprocess text data</a></span></li><li><span><a href=\"#Word2Vec-processing\" data-toc-modified-id=\"Word2Vec-processing-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Word2Vec processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-text-data-for-W2V-modeling\" data-toc-modified-id=\"Prepare-text-data-for-W2V-modeling-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Prepare text data for W2V modeling</a></span></li><li><span><a href=\"#Train-Word2Vec-model\" data-toc-modified-id=\"Train-Word2Vec-model-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Train Word2Vec model</a></span></li></ul></li><li><span><a href=\"#Vectorize-clinic-notes\" data-toc-modified-id=\"Vectorize-clinic-notes-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Vectorize clinic notes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vectorize-notes-and-store-as-text-data-frame\" data-toc-modified-id=\"Vectorize-notes-and-store-as-text-data-frame-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Vectorize notes and store as text data frame</a></span></li><li><span><a href=\"#Append-vectorized-notes-to-train-and-test-X-dataframes\" data-toc-modified-id=\"Append-vectorized-notes-to-train-and-test-X-dataframes-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Append vectorized notes to train and test X dataframes</a></span></li></ul></li><li><span><a href=\"#SMOTE-Balancing\" data-toc-modified-id=\"SMOTE-Balancing-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>SMOTE Balancing</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Modeling</a></span></li><li><span><a href=\"#Oversample-the-minority-class\" data-toc-modified-id=\"Oversample-the-minority-class-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Oversample the minority class</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-2-models\" data-toc-modified-id=\"Train-2-models-10.1\"><span class=\"toc-item-num\">10.1&nbsp;&nbsp;</span>Train 2 models</a></span></li><li><span><a href=\"#Pickle-all-of-the-models-we-need-for-the-dashboard\" data-toc-modified-id=\"Pickle-all-of-the-models-we-need-for-the-dashboard-10.2\"><span class=\"toc-item-num\">10.2&nbsp;&nbsp;</span>Pickle all of the models we need for the dashboard</a></span></li></ul></li><li><span><a href=\"#Try-random-forest-on-non-normalized-values\" data-toc-modified-id=\"Try-random-forest-on-non-normalized-values-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Try random forest on non-normalized values</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# For interacting with PostgreSQL database for mimic queries\n",
    "import psycopg2\n",
    "\n",
    "# Ploting functions\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "plotly.tools.set_credentials_file(username='mlpaff', api_key='lYV8hhGxZlP988tplymj')\n",
    "plotly.tools.set_config_file(world_readable=True,\n",
    "                             sharing='public')\n",
    "\n",
    "from IPython.core.pylabtools import figsize\n",
    "import matplotlib.pyplot as plt\n",
    "figsize(20, 10)\n",
    "plt.style.use(['dark_background'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "color_set = ['#A9CA59', '#6582C4', '#62C9BC', '#F58D50', '#2AD7F4',\n",
    "             '#AB3EED', '#FF6CB2', '#FFA466', '#FFE256', '#47EAAC', '#2AD7F4', '#3C8CF9']\n",
    "\n",
    "# specify user and database for SQL queries\n",
    "sqluser = 'mattmimic'\n",
    "dbname = 'mimic'\n",
    "set_schema = '--search_path=mimiciii'\n",
    "\n",
    "# Connect to the database\n",
    "# con = psycopg2.connect(dbname = dbname, user = sqluser, options = set_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in preprocessed patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_processed = pd.read_csv('../admission_processed.csv', parse_dates=['admittime', 'dischtime', 'deathtime', 'edregtime', 'edouttime', 'next_admittime', 'dob'], date_parser=pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structured features that will be included in the model\n",
    "feature_set_1 = ['admission_type', 'total_prior_admits','gender', 'age', 'length_of_stay', 'num_medications', 'num_lab_tests', 'perc_tests_abnormal', 'num_diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only those features that we want and add in hadm_id (to merge notes on)\n",
    "adm_processed = adm_processed[['hadm_id', 'subject_id', 'days_next_admit'] + feature_set_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical features and scale numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning:\n",
      "\n",
      "Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining dictionaries for encoding\n",
    "admin_type_dict = {'EMERGENCY': 0, 'URGENT': 0, 'ELECTIVE': 1}\n",
    "gender_dict = {'M': 0, 'F': 1}\n",
    "\n",
    "# Mapping dictionaries to binary features\n",
    "adm_processed['admission_type'] = adm_processed['admission_type'].map(admin_type_dict).astype(int)\n",
    "adm_processed['gender'] = adm_processed['gender'].map(gender_dict).astype(int)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = MinMaxScaler()\n",
    "standard_cols = ['total_prior_admits', 'age', 'length_of_stay', 'num_medications', 'num_lab_tests', 'num_diagnosis']\n",
    "\n",
    "# Normalizing the numeric columns\n",
    "adm_processed[standard_cols] = scaler.fit_transform(adm_processed[standard_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in NOTEEVENTS table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartdate</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>cgid</th>\n",
       "      <th>iserror</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>804333</td>\n",
       "      <td>5289</td>\n",
       "      <td>194762.0</td>\n",
       "      <td>2110-11-05</td>\n",
       "      <td>2110-11-05 06:52:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[**2110-11-5**] 6:52 AM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804334</td>\n",
       "      <td>13993</td>\n",
       "      <td>180704.0</td>\n",
       "      <td>2103-11-07</td>\n",
       "      <td>2103-11-07 06:53:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[**2103-11-7**] 6:53 AM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>804467</td>\n",
       "      <td>4599</td>\n",
       "      <td>109574.0</td>\n",
       "      <td>2120-10-31</td>\n",
       "      <td>2120-10-31 12:37:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CT PERITONEAL DRAINAGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[**2120-10-31**] 12:37 PM\\n CT PERITONEAL DRAI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>804108</td>\n",
       "      <td>9090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2180-09-25</td>\n",
       "      <td>2180-09-25 08:20:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>UGI SGL CONTRAST W/ KUB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[**2180-9-25**] 8:20 AM\\n UGI SGL CONTRAST W/ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>804109</td>\n",
       "      <td>19621</td>\n",
       "      <td>102739.0</td>\n",
       "      <td>2193-09-23</td>\n",
       "      <td>2193-09-23 00:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>PERSANTINE MIBI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>PERSANTINE MIBI                               ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  subject_id   hadm_id  chartdate           charttime storetime  \\\n",
       "0  804333        5289  194762.0 2110-11-05 2110-11-05 06:52:00       NaT   \n",
       "1  804334       13993  180704.0 2103-11-07 2103-11-07 06:53:00       NaT   \n",
       "2  804467        4599  109574.0 2120-10-31 2120-10-31 12:37:00       NaT   \n",
       "3  804108        9090       NaN 2180-09-25 2180-09-25 08:20:00       NaT   \n",
       "4  804109       19621  102739.0 2193-09-23 2193-09-23 00:00:00       NaT   \n",
       "\n",
       "    category              description  cgid iserror  \\\n",
       "0  Radiology      CHEST (PORTABLE AP)   NaN    None   \n",
       "1  Radiology      CHEST (PORTABLE AP)   NaN    None   \n",
       "2  Radiology   CT PERITONEAL DRAINAGE   NaN    None   \n",
       "3  Radiology  UGI SGL CONTRAST W/ KUB   NaN    None   \n",
       "4  Radiology          PERSANTINE MIBI   NaN    None   \n",
       "\n",
       "                                                text  \n",
       "0  [**2110-11-5**] 6:52 AM\\n CHEST (PORTABLE AP) ...  \n",
       "1  [**2103-11-7**] 6:53 AM\\n CHEST (PORTABLE AP) ...  \n",
       "2  [**2120-10-31**] 12:37 PM\\n CT PERITONEAL DRAI...  \n",
       "3  [**2180-9-25**] 8:20 AM\\n UGI SGL CONTRAST W/ ...  \n",
       "4  PERSANTINE MIBI                               ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "con = psycopg2.connect(dbname = dbname, user = sqluser, options = set_schema)\n",
    "query = 'SELECT * FROM noteevents;'\n",
    "notes = pd.read_sql_query(query, con)\n",
    "con.close()\n",
    "notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Multiple discharge summaries per admission",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9ddbb2abef34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdis_notes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Discharge summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdis_notes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hadm_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Multiple discharge summaries per admission'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Multiple discharge summaries per admission"
     ]
    }
   ],
   "source": [
    "# Filter to discharge summary notes only\n",
    "dis_notes = notes[notes['category'] == 'Discharge summary'].copy()\n",
    "\n",
    "assert dis_notes.duplicated(['hadm_id']).sum() == 0, 'Multiple discharge summaries per admission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just the last discharge summaries by hadm_id\n",
    "last_dis_notes = dis_notes.groupby(['subject_id', 'hadm_id']).nth(-1).reset_index()\n",
    "assert last_dis_notes.duplicated(['hadm_id']).sum() == 0, 'Multiple discharge summaries per admission'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_dis_notes.head()\n",
    "note_features = ['subject_id', 'hadm_id', 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge notes table with adm_processed table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge notes table with processed structural data\n",
    "adm_notes = adm_processed.merge(last_dis_notes[note_features], on = ['subject_id', 'hadm_id'], how = 'left')\n",
    "\n",
    "# assert len(admissions) == len(adm_notes), 'Number of rows increased'\n",
    "\n",
    "# Generate output label for readmissions under 30 days\n",
    "adm_notes['output_label'] = (adm_notes['days_next_admit'] < 30).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>days_next_admit</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>total_prior_admits</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>num_lab_tests</th>\n",
       "      <th>perc_tests_abnormal</th>\n",
       "      <th>num_diagnosis</th>\n",
       "      <th>text</th>\n",
       "      <th>output_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185777</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523442</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.043219</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>0.240816</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>Admission Date:  [**2191-3-16**]     Discharge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107064</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.721418</td>\n",
       "      <td>0.055537</td>\n",
       "      <td>0.109538</td>\n",
       "      <td>0.041645</td>\n",
       "      <td>0.448517</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>Admission Date: [**2175-5-30**]        Dischar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194540</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.548635</td>\n",
       "      <td>0.086639</td>\n",
       "      <td>0.067064</td>\n",
       "      <td>0.032091</td>\n",
       "      <td>0.104072</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>Admission Date:  [**2178-4-16**]              ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143045</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.436122</td>\n",
       "      <td>0.023266</td>\n",
       "      <td>0.061848</td>\n",
       "      <td>0.026037</td>\n",
       "      <td>0.298050</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>Name:  [**Known lastname 9900**], [**Known fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194023</td>\n",
       "      <td>17</td>\n",
       "      <td>128.920833</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519159</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.040238</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>Admission Date:  [**2134-12-27**]             ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id  subject_id  days_next_admit  admission_type  total_prior_admits  \\\n",
       "0   185777           4              NaN               0                 0.0   \n",
       "1   107064           6              NaN               1                 0.0   \n",
       "2   194540          11              NaN               0                 0.0   \n",
       "3   143045          13              NaN               0                 0.0   \n",
       "4   194023          17       128.920833               1                 0.0   \n",
       "\n",
       "   gender       age  length_of_stay  num_medications  num_lab_tests  \\\n",
       "0       1  0.523442        0.026332         0.043219       0.017723   \n",
       "1       1  0.721418        0.055537         0.109538       0.041645   \n",
       "2       1  0.548635        0.086639         0.067064       0.032091   \n",
       "3       1  0.436122        0.023266         0.061848       0.026037   \n",
       "4       1  0.519159        0.014824         0.040238       0.013857   \n",
       "\n",
       "   perc_tests_abnormal  num_diagnosis  \\\n",
       "0             0.240816       0.230769   \n",
       "1             0.448517       0.205128   \n",
       "2             0.104072       0.025641   \n",
       "3             0.298050       0.128205   \n",
       "4             0.296875       0.102564   \n",
       "\n",
       "                                                text  output_label  \n",
       "0  Admission Date:  [**2191-3-16**]     Discharge...             0  \n",
       "1  Admission Date: [**2175-5-30**]        Dischar...             0  \n",
       "2  Admission Date:  [**2178-4-16**]              ...             0  \n",
       "3  Name:  [**Known lastname 9900**], [**Known fir...             0  \n",
       "4  Admission Date:  [**2134-12-27**]             ...             0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm_notes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of admissions without notes: 0.0232\n",
      "number of patients that were re-admitted within 30 days: 2779\n",
      "fraction of patients re-admitted within 30 days: 0.0672441745106105\n"
     ]
    }
   ],
   "source": [
    "print('Fraction of admissions without notes:', round(adm_notes.text.isnull().sum() / len(adm_notes), 4))\n",
    "print('number of patients that were re-admitted within 30 days:', len(adm_notes[adm_notes['output_label'] == 1]))\n",
    "print('fraction of patients re-admitted within 30 days:', len(adm_notes[adm_notes['output_label'] == 1]) / len(adm_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33061, 10) (8266, 10) (33061, 1) (8266, 1)\n"
     ]
    }
   ],
   "source": [
    "# shuffle the samples\n",
    "adm_notes = adm_notes.sample(n = len(adm_notes), random_state=42)\n",
    "adm_notes.reset_index(drop=True, inplace=True)\n",
    "\n",
    "target = adm_notes[['output_label']]\n",
    "data = adm_notes[feature_set_1 + ['text']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state = 0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    ''' Preprocesses the text by filling not a number and replacing new lines ('\\n') and carriage returns ('\\r')\n",
    "    '''\n",
    "    \n",
    "    df['text'] = df['text'].fillna(' ')\n",
    "    df['text'] = df['text'].str.replace('\\n', ' ')\n",
    "    df['text'] = df['text'].str.replace('\\r', ' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train = preprocess_text(X_test), preprocess_text(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "tokenizer = nltk.data.load('nltk:tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare text data for W2V modeling\n",
    "- Here we want to convert everything to lowercase and convert to list of sentences while droping stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = ['the','and','to','of','was','with','a','on','in','for','name',\n",
    "                 'is','patient','s','he','at','as','or','one','she','his','her','am',\n",
    "                 'were','you','pt','pm','by','be','had','your','this','date',\n",
    "                'from','there','an','that','p','are','have','has','h','but','o',\n",
    "                'namepattern','which','every','also', 'b', 'i', 'd', 'admission', 'q', 't']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2vTokenizer(sentence):\n",
    "    ''' Tokenize the text by replacing punctuations and numbers with spaces and lowercase all words\n",
    "    '''\n",
    "    punc_list = string.punctuation + '0123456789'\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, ' '))\n",
    "    text = str(sentence).lower().translate(t)\n",
    "    tokens = [x for x in nltk.word_tokenize(text.strip()) if x not in my_stop_words]\n",
    "#     tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def notes_to_sentences(notes, tokenizer, remove_stopwords=False):\n",
    "    ''' Split text data into tokenized list of sentences\n",
    "    '''\n",
    "    try:\n",
    "        # use NLTK tokenizer to split the text into sentences\n",
    "        raw_sentences = tokenizer.tokenize(notes)\n",
    "        \n",
    "        # Loop over each sentence\n",
    "        sentences = []\n",
    "        for sent in raw_sentences:\n",
    "            # if sentence is empty, skip it\n",
    "            if len(sent) > 0:\n",
    "                tokens = [x for x in w2vTokenizer(sent.strip()) if x not in my_stop_words]\n",
    "                if len(tokens) > 0:\n",
    "                    sentences.append(tokens)\n",
    "        # Return the list of sentences\n",
    "        return sentences\n",
    "    except:\n",
    "        print('nope')\n",
    "        \n",
    "def prepareW2Vtext(notes_list):\n",
    "    ''' From the text corpus (list of tokenized sentences generated from all text data), Tokenize the data\n",
    "    '''\n",
    "    \n",
    "    sentences = []\n",
    "    for note in notes_list:\n",
    "        note = str(note)\n",
    "        if len(note) > 0:\n",
    "            sentences += notes_to_sentences(note, tokenizer)\n",
    "    return(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_list = list(X_train['text'])\n",
    "processed_text = prepareW2Vtext(notes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3354537\n"
     ]
    }
   ],
   "source": [
    "print(len(processed_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 400      # Word vector dimentionality\n",
    "min_word_count = 50     # min word count\n",
    "num_workers = 4         # number of threads to run in parallel\n",
    "context = 4             # Context window size\n",
    "downsampling = 1e-3     # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vModel = Word2Vec(processed_text, workers=num_workers, \\\n",
    "                          size=num_features, min_count=min_word_count, \\\n",
    "                          window=context, sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v = dict(zip(w2vModel.wv.index2word, w2vModel.wv.vectors))\n",
    "\n",
    "w2vModel.wv.save_word2vec_format('mimic_w2v_model.bin')\n",
    "\n",
    "# Load model\n",
    "# model = Word2Vec.load('mimic_w2v_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize clinic notes\n",
    "- Using the Word2Vec model trained on the clinic notes corpus, vectorize each patients discharge summary notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_clinic_notes(note):\n",
    "    ''' Tokenize the patient text by replacing punctuations and numbers with spaces and lowercase all words\n",
    "    '''\n",
    "    punc_list = string.punctuation + '0123456789'\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, ' '))\n",
    "    text = str(note).lower().translate(t)\n",
    "#     tokens = (x for x in word_tokenize(text.strip()) if x not in my_stop_words)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_X = []\n",
    "        for document in X:\n",
    "            doc = [word for word in document if word in self.vocab]\n",
    "            transformed_X.append(doc)\n",
    "        return transformed_X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "            \n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    ''' Convert notes to vector\n",
    "    '''\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(word2vec.wv.vectors[0])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "#         doc = [word for word in X if word in self.word2vec.wv.vocab]\n",
    "        X = MyTokenizer(self.word2vec.wv.vocab).fit_transform(X)\n",
    "    \n",
    "        return np.array([\n",
    "                    np.mean([self.word2vec.wv[w] for w in document] or \n",
    "                            [np.zeros(self.dim)], axis = 0) for document in X\n",
    "        ])\n",
    "#         return np.mean(self.word2vec[doc], axis = 0)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the clinic notes so that they can be vectorized: Do this for X_train and X_test\n",
    "X_train['tokens'], X_test['tokens'] = X_train['text'].apply(lambda x: tokenize_clinic_notes(x)), X_test['text'].apply(lambda x: tokenize_clinic_notes(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize notes and store as text data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vVectorizer = MeanEmbeddingVectorizer(w2vModel)\n",
    "\n",
    "# Get the transformed, vectorized text data\n",
    "X_train_vectors, X_test_vectors = pd.DataFrame(w2vVectorizer.fit_transform(X_train['tokens'])), pd.DataFrame(w2vVectorizer.fit_transform(X_test['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_vectors[X_train_vectors.columns[-400:]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append vectorized notes to train and test X dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf, X_test_tf = pd.concat([X_train.reset_index(drop=True), X_train_vectors], axis = 1),  pd.concat([X_test.reset_index(drop=True), X_test_vectors], axis = 1)\n",
    "\n",
    "# Drop text data\n",
    "X_train_tf.drop(['text', 'tokens'], axis = 1, inplace=True)\n",
    "X_test_tf.drop(['text', 'tokens'], axis = 1, inplace=True)\n",
    "\n",
    "# Check that the number of rows has not changed\n",
    "assert X_train_tf.shape[0] == X_train.shape[0], 'Train data frame shape has changed'\n",
    "assert X_test_tf.shape[0] == X_test.shape[0], 'Test data frame shape has changed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33061, 409)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE Balancing\n",
    "- Do some undersampling/oversampling on the training data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33061, 409)\n",
      "(33061, 1)\n",
      "Original train dataset shape Counter({0: 30832, 1: 2229})\n",
      "Original test dataset shape Counter({0: 7716, 1: 550})\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tf.shape)\n",
    "print(y_train.shape)\n",
    "print('Original train dataset shape {}'.format(Counter(y_train['output_label'])))\n",
    "print('Original test dataset shape {}'.format(Counter(y_test['output_label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train dataset shape Counter({'output_label': 1})\n",
      "Original test dataset shape Counter({'output_label': 1})\n",
      "New train dataset shape Counter({1: 30741, 0: 12698})\n"
     ]
    }
   ],
   "source": [
    "print('Original train dataset shape {}'.format(Counter(y_train['output_label'])))\n",
    "print('Original test dataset shape {}'.format(Counter(y_test['output_label'])))\n",
    "\n",
    "\n",
    "def balancing(X, Y, undersample = None):\n",
    "    # Oversampling with SMOTE\n",
    "    smt = SMOTE(random_state=20)\n",
    "    if undersample:\n",
    "        smt = SMOTEENN(random_state=20)\n",
    "\n",
    "    X_new, Y_new = smt.fit_sample(X, Y)\n",
    "    print('New train dataset shape {}'.format(Counter(Y_new)))\n",
    "    X_new = pd.DataFrame(X_new, columns = list(X.columns))\n",
    "    return X_new, Y_new\n",
    "\n",
    "X_train_balanced, y_train_balanced = balancing(X_train_tf, y_train['output_label'], undersample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "- Train 3 models:\n",
    "    1. Using only structural data\n",
    "    2. Using only notes data\n",
    "    3. Using all data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "from scipy import interp\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def DTCGrid(X_train, X_test, Y_train, Y_test, model):\n",
    "    if model == 'lr':\n",
    "        pipeline = Pipeline([('clf',LogisticRegression(penalty = 'l2', max_iter=1000, random_state = 20000, solver='lbfgs'))])\n",
    "        param_dist = {'clf__C': [0.0001, 0.0005, 0.001, 0.0033, 0.0066, 0.01, 0.033, 0.066, 0.1, 0.33, 1, 3, 6, 10, 100]}\n",
    "    \n",
    "    if model == 'dt':\n",
    "        pipeline = Pipeline([('clf',DecisionTreeClassifier(criterion='entropy', random_state=20000))])\n",
    "        # specify parameters and distributions to sample from\n",
    "        param_dist = {'clf__max_depth': sp_randint(20, 30),\n",
    "                 'clf__min_samples_split': sp_randint(2, 11)\n",
    "                    }\n",
    "    if model == 'rf':\n",
    "        pipeline = Pipeline([('clf',RandomForestClassifier(criterion='entropy', random_state=20000))])\n",
    "        # specify parameters and distributions to sample from\n",
    "        param_dist = {'clf__max_depth': sp_randint(20, 30),\n",
    "                     'clf__max_features': sp_randint(1, X_train.shape[1]),\n",
    "                 'clf__min_samples_split': sp_randint(2, 11)\n",
    "                    }\n",
    "    # run randomized search\n",
    "    n_iter_search = 20\n",
    "    rand_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, random_state=20000,\n",
    "                                    n_iter=n_iter_search, cv = 10, n_jobs=-1,verbose=1, scoring='recall')\n",
    "    rand_search.fit(X_train, Y_train)\n",
    "    print('Best score: %0.3f' % rand_search.best_score_)\n",
    "    print('Best parameters set:')\n",
    "    best_parameters = rand_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(param_dist.keys()):\n",
    "        print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    predictions = rand_search.predict(X_test)\n",
    "    print(classification_report(Y_test, predictions))\n",
    "    print(\"AUC is {0:.2f}\".format(roc_auc_score(Y_test, predictions)))\n",
    "    print(confusion_matrix(Y_test, predictions))\n",
    "    return rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning:\n",
      "\n",
      "The total space of parameters 15 is smaller than n_iter=20. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.704\n",
      "Best parameters set:\n",
      "\tclf__C: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81      7716\n",
      "           1       0.12      0.58      0.20       550\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      8266\n",
      "   macro avg       0.54      0.64      0.50      8266\n",
      "weighted avg       0.90      0.69      0.77      8266\n",
      "\n",
      "AUC is 0.64\n",
      "[[5384 2332]\n",
      " [ 230  320]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   10.3s finished\n"
     ]
    }
   ],
   "source": [
    "# With SMOTE and Undersampling\n",
    "best_estimator = DTCGrid(X_train_tf[feature_set_1], X_test_tf[feature_set_1], y_train['output_label'], y_test['output_label'], model = 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_estimator = DTCGrid(X_train_tf[feature_set_1], X_test_tf[feature_set_1], y_train['output_label'], y_test['output_label'], model = 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a logistic regression on just the vectorized text data\n",
    "nlp_model = DTCGrid(X_train_tf[X_train_tf.columns[-400:]], X_test_tf[X_test_tf.columns[-400:]], y_train['output_label'], y_test['output_label'], model = 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning:\n",
      "\n",
      "The total space of parameters 15 is smaller than n_iter=20. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.725\n",
      "Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.68      0.80      7716\n",
      "           1       0.13      0.65      0.21       550\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      8266\n",
      "   macro avg       0.54      0.66      0.50      8266\n",
      "weighted avg       0.91      0.68      0.76      8266\n",
      "\n",
      "AUC is 0.66\n",
      "[[5247 2469]\n",
      " [ 195  355]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge. Increase the number of iterations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = DTCGrid(X_train_tf, X_test_tf, y_train['output_label'], y_test['output_label'], model = 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_estimator = DTCGrid(X_train_tf[X_train_tf.columns[-400:]], X_test_tf[X_test_tf.columns[-400:]], y_train, y_test, model = 'dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge. Increase the number of iterations.\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge. Increase the number of iterations.\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge. Increase the number of iterations.\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge. Increase the number of iterations.\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge. Increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 69.17%\n",
      "Test Set score: 68.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge. Increase the number of iterations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lr = LR(C = 100, penalty = 'l2', class_weight='balanced', random_state = 3, solver=\"lbfgs\")\n",
    "\n",
    "\n",
    "print(\"Cross Validation Score: {:.2%}\".format(np.mean(cross_val_score(model_lr, X_train_tf, y_train['output_label'], cv=5))))\n",
    "# logreg.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "model_lr.fit(X_train_tf, y_train['output_label'])\n",
    "print(\"Test Set score: {:.2%}\".format(model_lr.score(X_test_tf, y_test['output_label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.68\n",
      "Precision is 0.12\n",
      "Recall is 0.61\n",
      "AUC is 0.65\n",
      "[[5322 2394]\n",
      " [ 212  338]]\n"
     ]
    }
   ],
   "source": [
    "y_test_preds = model_lr.predict(X_test_tf)\n",
    "\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, y_test_preds)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_test, y_test_preds)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_test, y_test_preds)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_test, y_test_preds)))\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search cv \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# def get_lr_hyperparams(x, y, nfolds):\n",
    "#     scoring = {'AUC': 'roc_auc', \n",
    "#                'prec': 'precision',\n",
    "#                'recall': 'recall'}\n",
    "#     param_grid = {'C': [0.0001, 0.0005, 0.001, 0.0033, 0.0066, 0.01, 0.033, 0.066, 0.1, 0.33, 1, 3, 6, 10, 100]}\n",
    "#     grid_search = GridSearchCV(LR(penalty='l1', solver='saga', class_weight='balanced', random_state=5, max_iter=100), \n",
    "#                                param_grid, scoring=scoring, cv=nfolds, refit='recall')\n",
    "#     grid_search.fit(x, y)\n",
    "#     grid_search.best_params_\n",
    "#     return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 30832), (1, 30832)]\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_tf, y_train['output_label'])\n",
    "\n",
    "X_resampled = pd.DataFrame(X_resampled, columns = X_train_tf.columns)\n",
    "\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.68\n",
      "Precision is 0.12\n",
      "Recall is 0.62\n",
      "AUC is 0.65\n",
      "[[5316 2400]\n",
      " [ 211  339]]\n"
     ]
    }
   ],
   "source": [
    "y_test_preds = model_lr.predict(X_test_tf)\n",
    "\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(y_test, y_test_preds)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(y_test, y_test_preds)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(y_test, y_test_preds)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(y_test, y_test_preds)))\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 2 models\n",
    "\n",
    "- Model 1: Using only structural features\n",
    "- Model 2: Adding in discharge notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning:\n",
      "\n",
      "The total space of parameters 15 is smaller than n_iter=20. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.676\n",
      "Best parameters set:\n",
      "\tclf__C: 0.0001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.54      0.69      7716\n",
      "           1       0.09      0.67      0.17       550\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      8266\n",
      "   macro avg       0.53      0.61      0.43      8266\n",
      "weighted avg       0.90      0.55      0.66      8266\n",
      "\n",
      "AUC is 0.61\n",
      "[[4196 3520]\n",
      " [ 181  369]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   12.4s finished\n"
     ]
    }
   ],
   "source": [
    "struct_model = DTCGrid(X_resampled[feature_set_1], X_test_tf[feature_set_1], y_resampled, y_test['output_label'], model = 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:271: UserWarning:\n",
      "\n",
      "The total space of parameters 15 is smaller than n_iter=20. Running 15 iterations. For exhaustive searches, use GridSearchCV.\n",
      "\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 10.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.706\n",
      "Best parameters set:\n",
      "\tclf__C: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.80      7716\n",
      "           1       0.12      0.62      0.21       550\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      8266\n",
      "   macro avg       0.54      0.65      0.51      8266\n",
      "weighted avg       0.91      0.68      0.76      8266\n",
      "\n",
      "AUC is 0.65\n",
      "[[5320 2396]\n",
      " [ 210  340]]\n"
     ]
    }
   ],
   "source": [
    "bootstrap_model = DTCGrid(X_resampled, X_test_tf, y_resampled, y_test['output_label'], model = 'lr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle all of the models we need for the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save struct model\n",
    "pickle.dump(struct_model, open('model1.pkl', 'wb'))\n",
    "\n",
    "# save nlp model\n",
    "pickle.dump(bootstrap_model, open('nlp_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try random forest on non-normalized values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_norm_adm = pd.read_csv('../admission_processed.csv', parse_dates=['admittime', 'dischtime', 'deathtime', 'edregtime', 'edouttime', 'next_admittime', 'dob'], date_parser=pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_norm_adm = no_norm_adm[['hadm_id', 'subject_id', 'days_next_admit'] + feature_set_1]\n",
    "\n",
    "# Defining dictionaries for encoding\n",
    "admin_type_dict = {'EMERGENCY': 0, 'URGENT': 0, 'ELECTIVE': 1}\n",
    "gender_dict = {'M': 0, 'F': 1}\n",
    "\n",
    "# Mapping dictionaries to binary features\n",
    "no_norm_adm['admission_type'] = no_norm_adm['admission_type'].map(admin_type_dict).astype(int)\n",
    "no_norm_adm['gender'] = no_norm_adm['gender'].map(gender_dict).astype(int)\n",
    "\n",
    "# Generate output label for readmissions under 30 days\n",
    "no_norm_adm['output_label'] = (no_norm_adm['days_next_admit'] < 30).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>days_next_admit</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>total_prior_admits</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>num_lab_tests</th>\n",
       "      <th>perc_tests_abnormal</th>\n",
       "      <th>num_diagnosis</th>\n",
       "      <th>output_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185777</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.843943</td>\n",
       "      <td>7.759028</td>\n",
       "      <td>59</td>\n",
       "      <td>245.0</td>\n",
       "      <td>0.240816</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107064</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.938398</td>\n",
       "      <td>16.364583</td>\n",
       "      <td>148</td>\n",
       "      <td>573.0</td>\n",
       "      <td>0.448517</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194540</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.146475</td>\n",
       "      <td>25.529167</td>\n",
       "      <td>91</td>\n",
       "      <td>442.0</td>\n",
       "      <td>0.104072</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143045</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39.863107</td>\n",
       "      <td>6.855556</td>\n",
       "      <td>84</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0.298050</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194023</td>\n",
       "      <td>17</td>\n",
       "      <td>128.920833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.452430</td>\n",
       "      <td>4.368056</td>\n",
       "      <td>55</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id  subject_id  days_next_admit  admission_type  total_prior_admits  \\\n",
       "0   185777           4              NaN               0                   0   \n",
       "1   107064           6              NaN               1                   0   \n",
       "2   194540          11              NaN               0                   0   \n",
       "3   143045          13              NaN               0                   0   \n",
       "4   194023          17       128.920833               1                   0   \n",
       "\n",
       "   gender        age  length_of_stay  num_medications  num_lab_tests  \\\n",
       "0       1  47.843943        7.759028               59          245.0   \n",
       "1       1  65.938398       16.364583              148          573.0   \n",
       "2       1  50.146475       25.529167               91          442.0   \n",
       "3       1  39.863107        6.855556               84          359.0   \n",
       "4       1  47.452430        4.368056               55          192.0   \n",
       "\n",
       "   perc_tests_abnormal  num_diagnosis  output_label  \n",
       "0             0.240816              9             0  \n",
       "1             0.448517              8             0  \n",
       "2             0.104072              1             0  \n",
       "3             0.298050              5             0  \n",
       "4             0.296875              4             0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_norm_adm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33061, 9) (8266, 9) (33061, 1) (8266, 1)\n"
     ]
    }
   ],
   "source": [
    "# shuffle the samples\n",
    "no_norm_adm = no_norm_adm.sample(n = len(no_norm_adm), random_state=42)\n",
    "no_norm_adm.reset_index(drop=True, inplace=True)\n",
    "\n",
    "no_norm_target = no_norm_adm[['output_label']]\n",
    "no_norm_data = no_norm_adm[feature_set_1]\n",
    "\n",
    "nn_X_train, nn_X_test, nn_y_train, nn_y_test = train_test_split(no_norm_data, no_norm_target, test_size=0.2, random_state = 0)\n",
    "print(nn_X_train.shape, nn_X_test.shape, nn_y_train.shape, nn_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_X_train_tf, nn_X_test_tf = pd.concat([nn_X_train.reset_index(drop=True), X_train_vectors], axis=1), pd.concat([nn_X_test.reset_index(drop=True), X_test_vectors], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33061, 409) (8266, 409)\n"
     ]
    }
   ],
   "source": [
    "print(nn_X_train_tf.shape, nn_X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 30832), (1, 30832)]\n"
     ]
    }
   ],
   "source": [
    "# Oversample trainset\n",
    "nn_X_resampled, nn_y_resampled = ros.fit_resample(nn_X_train_tf, nn_y_train['output_label'])\n",
    "\n",
    "nn_X_resampled = pd.DataFrame(nn_X_resampled, columns=nn_X_train_tf.columns)\n",
    "\n",
    "print(sorted(Counter(nn_y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.5min finished\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 1.000\n",
      "Best parameters set:\n",
      "\tclf__max_depth: 28\n",
      "\tclf__max_features: 4\n",
      "\tclf__min_samples_split: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      7716\n",
      "           1       0.20      0.05      0.08       550\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      8266\n",
      "   macro avg       0.57      0.52      0.52      8266\n",
      "weighted avg       0.89      0.92      0.90      8266\n",
      "\n",
      "AUC is 0.52\n",
      "[[7598  118]\n",
      " [ 521   29]]\n"
     ]
    }
   ],
   "source": [
    "nn_bootstrap_model = DTCGrid(nn_X_resampled[feature_set_1], nn_X_test_tf[feature_set_1], nn_y_resampled, nn_y_test['output_label'], model = 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "1297.78px",
    "left": "133px",
    "top": "132.278px",
    "width": "369.41px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
